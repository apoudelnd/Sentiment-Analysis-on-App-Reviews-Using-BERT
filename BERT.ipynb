{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKWFTAL2w84Q"
      },
      "source": [
        "from collections import defaultdict"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kt3Yn1YZ6W3q",
        "outputId": "90d32e14-e642-4546-a6f7-715d915d3756"
      },
      "source": [
        "pip install transformers"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.11.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.19)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.46)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.3.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pvqjQbJ6Zs7"
      },
      "source": [
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "from matplotlib import rc\n",
        "from pylab import rcParams\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7Jo-F7ozej-",
        "outputId": "4a42176f-33d3-4b8f-ddf9-43178542220d"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt \n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "# rcParams['figure.figsize'] = 6,8\n",
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7ff5a647b190>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYFKOkxizaW4",
        "outputId": "e3ecfafe-3297-4876-f6e5-ada654b1473d"
      },
      "source": [
        "df = pd.read_csv(\"reviews.csv\")\n",
        "df.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16770, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svFCbFvYzraO",
        "outputId": "90c271b7-1b3f-43fc-bd97-a2a6bc91b588"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 16770 entries, 0 to 16769\n",
            "Data columns (total 12 columns):\n",
            " #   Column                Non-Null Count  Dtype \n",
            "---  ------                --------------  ----- \n",
            " 0   reviewId              16770 non-null  object\n",
            " 1   userName              16768 non-null  object\n",
            " 2   userImage             16770 non-null  object\n",
            " 3   content               16770 non-null  object\n",
            " 4   score                 16770 non-null  int64 \n",
            " 5   thumbsUpCount         16770 non-null  int64 \n",
            " 6   reviewCreatedVersion  14250 non-null  object\n",
            " 7   at                    16770 non-null  object\n",
            " 8   replyContent          9042 non-null   object\n",
            " 9   repliedAt             9042 non-null   object\n",
            " 10  sortOrder             16770 non-null  object\n",
            " 11  appId                 16770 non-null  object\n",
            "dtypes: int64(2), object(10)\n",
            "memory usage: 1.5+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "Z3RftC5nz16n",
        "outputId": "9256d869-9a3b-4454-ad5a-e0fd2af74454"
      },
      "source": [
        "sns.countplot(df.score)\n",
        "plt.xlabel ('review score')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'review score')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jkd4ZXsR3KTV"
      },
      "source": [
        "def to_sentiment(rating):\n",
        "  # rating = int (rating)\n",
        "  if rating <= 2:\n",
        "    return 0\n",
        "  elif rating == 3:\n",
        "    return 1\n",
        "  else:\n",
        "    return 2"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlFb00eg3hbH"
      },
      "source": [
        "df['sentiment'] = df.score.apply(to_sentiment) "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7HVI6DX33b_"
      },
      "source": [
        "class_names = ['negative', 'neutral', 'positive']"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "KOmj4vF-rdKb",
        "outputId": "2530ea3a-2ddf-4202-caf6-fd75090a4d01"
      },
      "source": [
        "df1 = df.sample(frac=.05, axis = 0)\n",
        "ax = sns.countplot(df1.sentiment)\n",
        "plt.xlabel('review sentiment')\n",
        "ax.set_xticklabels(class_names)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0, 0, 'negative'), Text(0, 0, 'neutral'), Text(0, 0, 'positive')]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqpJKsW8uctE",
        "outputId": "162b6fd1-fa0e-4f4b-afd5-14716fedf8b4"
      },
      "source": [
        "df1['sentiment'].value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    302\n",
              "0    286\n",
              "1    250\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "rgJpRKib3sxE",
        "outputId": "85bed7e3-85aa-4be8-b3e0-bb64fc58a6ba"
      },
      "source": [
        "ax = sns.countplot(df.sentiment)\n",
        "plt.xlabel('review sentiment')\n",
        "ax.set_xticklabels(class_names)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Text(0, 0, 'negative'), Text(0, 0, 'neutral'), Text(0, 0, 'positive')]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fxeRLfV7DK6"
      },
      "source": [
        "PRE_TRAINED_MODEL_NAME  = 'bert-base-cased'"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wwu1Wdd67EJZ"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SydGSkL358CU"
      },
      "source": [
        "tokenizer = transformers.BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YprvXsWe6-Br"
      },
      "source": [
        "sample_txt = \"When was I last outside? I am stuck at home for 2 weeks.\""
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3f4b3Rc73ke",
        "outputId": "83ac2d40-98f6-4dc8-9457-ac0112430a93"
      },
      "source": [
        "tokens = tokenizer.tokenize(sample_txt)\n",
        "print (tokens)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['When', 'was', 'I', 'last', 'outside', '?', 'I', 'am', 'stuck', 'at', 'home', 'for', '2', 'weeks', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YeFOHIe8Kcn",
        "outputId": "fe2025c6-e8a3-4b2f-da6f-1513761d8fe6"
      },
      "source": [
        "#tokens into corresponding ids!! \n",
        "\n",
        "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "print (f\"Sentence: {sample_txt}\")\n",
        "print (f\"Tokens: {tokens}\")\n",
        "print (f\"Token Ids: {token_ids}\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence: When was I last outside? I am stuck at home for 2 weeks.\n",
            "Tokens: ['When', 'was', 'I', 'last', 'outside', '?', 'I', 'am', 'stuck', 'at', 'home', 'for', '2', 'weeks', '.']\n",
            "Token Ids: [1332, 1108, 146, 1314, 1796, 136, 146, 1821, 5342, 1120, 1313, 1111, 123, 2277, 119]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEAKU0mQ92cc"
      },
      "source": [
        "# Special Tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdfNsEKi97AD",
        "outputId": "091190c2-d9d8-48f1-9588-f33baf8c1417"
      },
      "source": [
        "tokenizer.sep_token,tokenizer.sep_token_id"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[SEP]', 102)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wugpj4Ub-Am0",
        "outputId": "8c255811-a5cc-4082-ff4e-467757afdab8"
      },
      "source": [
        "tokenizer.cls_token,tokenizer.cls_token_id"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[CLS]', 101)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkvhW83M-GGr",
        "outputId": "8c95dce8-f6bc-43e8-97a9-b48a80c8cdc4"
      },
      "source": [
        "tokenizer.pad_token,tokenizer.pad_token_id"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[PAD]', 0)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGQzatN7-VcN",
        "outputId": "8feadf72-cf9c-4907-8717-38324d4413cb"
      },
      "source": [
        "tokenizer.unk_token,tokenizer.unk_token_id"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[UNK]', 100)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoK953_b-hGX",
        "outputId": "36ec0b91-e00a-4e33-a3b8-86753c38f8e0"
      },
      "source": [
        "encoding = tokenizer.encode_plus(sample_txt,\n",
        "                                 max_length=32,\n",
        "                                 add_special_tokens= True,\n",
        "                                 pad_to_max_length = True,\n",
        "                                 return_attention_mask = True,\n",
        "                                 return_token_type_ids=False,\n",
        "                                 return_tensors = 'pt')\n",
        "\n",
        "encoding.keys()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wD9pj3fGAAB7",
        "outputId": "a36f2920-68ef-487d-c3e7-c4b9dee794b1"
      },
      "source": [
        "encoding['input_ids'] \n",
        "print(len(encoding['input_ids'][0]))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tji0dd-6AKCa",
        "outputId": "87e1477d-2ae1-472b-864c-ad2d704ef316"
      },
      "source": [
        "len(encoding['input_ids'][0])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSMwlPWjAVg6",
        "outputId": "5a4ec847-c858-444b-bc2d-5287b9f20d23"
      },
      "source": [
        "encoding['attention_mask']"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOW4bRSqA4X7"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8muD9_q9BQll"
      },
      "source": [
        "# Choosing Sequence Length"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDHx3Q38BUSQ"
      },
      "source": [
        "token_lens = []\n",
        "for txt in df1.content:\n",
        "  tokens = tokenizer.encode(txt,max_length=512)\n",
        "  token_lens.append(len(tokens))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "xWKqXwoXBnmX",
        "outputId": "4aa6cbe1-6055-43a0-8f8a-09c17d625e82"
      },
      "source": [
        "sns.displot(token_lens)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<seaborn.axisgrid.FacetGrid at 0x7ff54d23a8d0>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2cNbtb5kDOwt"
      },
      "source": [
        "# Create a Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kUt3P8oGDRmq"
      },
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "  \n",
        "  def __init__(self, review, target, tokenizer, max_len):\n",
        "    self.review= review\n",
        "    self.target = target\n",
        "    self. tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "  \n",
        "  def __len__(self):\n",
        "    return len(self.review)\n",
        "\n",
        "  def __getitem__(self,item):\n",
        "    review = str(self.review[item])\n",
        "    target = self.target[item]\n",
        "\n",
        "    encoding = tokenizer.encode_plus(review,\n",
        "                                 max_length=self.max_len,\n",
        "                                 add_special_tokens= True,\n",
        "                                 pad_to_max_length = True,\n",
        "                                 return_attention_mask = True,\n",
        "                                 return_token_type_ids=False,\n",
        "                                 return_tensors = 'pt')\n",
        "    \n",
        "    return {\n",
        "        'review_txt': review,\n",
        "        'input_ids' : encoding['input_ids'].flatten(),\n",
        "        'attention_mask' : encoding['attention_mask'].flatten(),\n",
        "        'targets': torch.tensor(target,dtype=torch.long)\n",
        "    }\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdtRvRch12YF"
      },
      "source": [
        ""
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P51fPVcHDqUy"
      },
      "source": [
        "MAX_LEN = 160\n",
        "BATCH_SIZE = 10\n",
        "EPOCHS = 10"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dGU1rHdvGKmO"
      },
      "source": [
        "df_train, df_test = train_test_split(df1, test_size = 0.2, random_state = RANDOM_SEED)\n",
        "df_val, df_test = train_test_split(df_test, test_size = 0.5, random_state = RANDOM_SEED)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1n3xZGcKHOa9",
        "outputId": "26fd6851-81b5-40c4-a767-b5210cf1ffcd"
      },
      "source": [
        "df_train.shape,df_val.shape, df_test.shape"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((670, 13), (84, 13), (84, 13))"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swEgLwWbHZsx"
      },
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = GPReviewDataset(\n",
        "      review = df.content.to_numpy(),\n",
        "      target = df.sentiment.to_numpy(),\n",
        "      tokenizer = tokenizer,\n",
        "      max_len = max_len\n",
        "  )\n",
        "\n",
        "  return DataLoader(\n",
        "      ds,\n",
        "      batch_size = batch_size,\n",
        "      num_workers = 2\n",
        "  )\n"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5FhsU-bIhH1"
      },
      "source": [
        "train_data_loader = create_data_loader(df_train,tokenizer,MAX_LEN,BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_test,tokenizer,MAX_LEN,BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val,tokenizer,MAX_LEN,BATCH_SIZE)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDJxxB7yvzqC",
        "outputId": "2376879e-f9b0-4f7c-ca2d-c6dfb1396e8b"
      },
      "source": [
        "data = next(iter(test_data_loader))\n",
        "data.keys()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['review_txt', 'input_ids', 'attention_mask', 'targets'])"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eN1L2UKwTrT",
        "outputId": "2bfe3715-4e4e-4cbc-cd63-f17f76053e37"
      },
      "source": [
        "print (data['input_ids'].shape)\n",
        "print (data['attention_mask'].shape)\n",
        "data['attention_mask']\n",
        "\n",
        "print (len(data['input_ids']))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 160])\n",
            "torch.Size([10, 160])\n",
            "10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xGCKHuoO0jsr",
        "outputId": "ac5b7d31-2c95-40a8-a43d-f1278ff0bafb"
      },
      "source": [
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MZP57bD0zEu"
      },
      "source": [
        "last_hidden_state, pooled_output= bert_model(\n",
        "                                        input_ids = encoding['input_ids'],\n",
        "                                        attention_mask = encoding['attention_mask'],\n",
        "                                        return_dict = False\n",
        ")"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8yKfQya2OoZ",
        "outputId": "af4c275d-377e-4280-8fb7-557a1228c535"
      },
      "source": [
        "last_hidden_state.shape"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 32, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UaUxdKY4prx",
        "outputId": "1cf51938-0107-4286-d9ac-decbfbc8626b"
      },
      "source": [
        "pooled_output.shape"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTF0WVwl4saO",
        "outputId": "b5544d03-cfc3-4de4-d263-68ebc49851f7"
      },
      "source": [
        "bert_model.config.hidden_size"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "768"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVvd6-1H7dGV"
      },
      "source": [
        "# Building a Sentiment Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DGbXXHv7nra"
      },
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "\n",
        "  def __init__(self, n_classes):\n",
        "    super(SentimentClassifier,self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME,return_dict=False)\n",
        "    self.drop = nn.Dropout(0.3)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "    self.softmax = nn.Softmax(dim=1)\n",
        "  \n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(\n",
        "        input_ids = input_ids,\n",
        "        attention_mask = attention_mask\n",
        "    )\n",
        "\n",
        "    output = self.drop(pooled_output)\n",
        "    output = self.out(output)\n",
        "    return self.softmax(output)\n",
        "\n"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHnc5cBdg-NH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69ed658a-8fad-4ccc-b1f9-49cce901a9c1"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3mYF_t_gJMn",
        "outputId": "fd933052-6d73-4667-a39d-a035d1ee0ddc"
      },
      "source": [
        "model = SentimentClassifier(len(class_names))\n",
        "model = model.to(device)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWmV2SqDRGpt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef45ec3a-3c0c-4cd2-c7eb-09ab170e3618"
      },
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "\n",
        "print (input_ids.shape)\n",
        "print (attention_mask.shape)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([10, 160])\n",
            "torch.Size([10, 160])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MN5dxrqBrdjS",
        "outputId": "bbcae6ef-5c24-4bde-f0ec-f4fb5a912721"
      },
      "source": [
        "model(input_ids,attention_mask)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2359, 0.4089, 0.3551],\n",
              "        [0.2658, 0.2706, 0.4636],\n",
              "        [0.3906, 0.2203, 0.3891],\n",
              "        [0.1926, 0.4010, 0.4064],\n",
              "        [0.5859, 0.1972, 0.2169],\n",
              "        [0.2387, 0.4040, 0.3573],\n",
              "        [0.2648, 0.3365, 0.3988],\n",
              "        [0.3667, 0.2366, 0.3967],\n",
              "        [0.4125, 0.2029, 0.3846],\n",
              "        [0.3299, 0.1987, 0.4714]], device='cuda:0', grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KAanzxQvifY"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMynEvqKvmKu"
      },
      "source": [
        "EPOCHS =10\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "    optimizer,\n",
        "    num_warmup_steps =0,\n",
        "    num_training_steps = total_steps\n",
        ")\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3Kc_Sf5xmsz"
      },
      "source": [
        "def train_epoch(model,data_loader,loss_fn,optimizer,scheduler,n_examples):\n",
        "  model = model.train()\n",
        "  correct_prediction = 0\n",
        "\n",
        "  losses = []\n",
        "\n",
        "  for d in data_loader:\n",
        "    input_ids = d['input_ids'].to(device)\n",
        "    attention_mask = d['attention_mask'].to(device)\n",
        "    targets = d['targets'].to(device)\n",
        "\n",
        "    outputs = model(input_ids = input_ids,\n",
        "                    attention_mask = attention_mask)\n",
        "    \n",
        "    _,preds = torch.max(outputs,dim=1)\n",
        "    loss = loss_fn(outputs,targets)\n",
        "\n",
        "    correct_prediction += torch.sum (preds == targets)\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(),max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return correct_prediction.double() / n_examples,np.mean(losses )"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Ee-5Zw407Ks"
      },
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "\n",
        "  model = model.eval()\n",
        "  losses = []\n",
        "  correct_prediction = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d['input_ids'].to(device)\n",
        "      attention_mask = d['attention_mask'].to(device)\n",
        "      targets = d['targets'].to(device)\n",
        "\n",
        "      outputs = model(input_ids = input_ids,\n",
        "                      attention_mask = attention_mask)\n",
        "      \n",
        "      _,preds = torch.max(outputs,dim=1)\n",
        "      loss = loss_fn(outputs,targets)\n",
        "\n",
        "      correct_prediction += torch.sum (preds == targets)\n",
        "      losses.append(loss.item())\n",
        "\n",
        "    return correct_prediction.double() / n_examples,np.mean(losses )"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkKOfJHILtdo",
        "outputId": "258f3a61-f803-4f3a-bc00-ed81262efc96"
      },
      "source": [
        "len(df_train)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "670"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gi8-ymeR1371",
        "outputId": "cc707a97-9415-4f49-8380-6a64b211f2c2"
      },
      "source": [
        "history = defaultdict(list)\n",
        "\n",
        "best_accuracy = 0 \n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "\n",
        "    print (f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "    print ('-'*10)\n",
        "\n",
        "    train_acc, train_loss = train_epoch(\n",
        "        model, \n",
        "        train_data_loader,\n",
        "        loss_fn, \n",
        "        optimizer,\n",
        "        scheduler, \n",
        "        len(df_train)\n",
        "    )\n",
        "\n",
        "    print (f'Train loss {train_loss} accuracy {train_acc}')\n",
        "    \n",
        "    val_acc, val_loss = train_epoch (\n",
        "        model, \n",
        "        train_data_loader,\n",
        "        loss_fn, \n",
        "        optimizer,\n",
        "        scheduler, \n",
        "        len(df_train)\n",
        "    )\n",
        "    \n",
        "    print(f'Train loss {val_loss} accuracy {val_acc}')\n",
        "    print()\n",
        "\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['train_loss'].append(train_loss)\n",
        "    \n",
        "    history['val_acc'].append(val_acc)\n",
        "    history['val_loss'].append(val_loss)\n",
        "\n",
        "    if val_acc > best_accuracy:\n",
        "      torch.save(model.state_dict(),'best_model_dtate.bin')\n",
        "      best_accuracy = val_acc\n"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 1.106000861125206 accuracy 0.33432835820895523\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.9879015799778611 accuracy 0.5447761194029851\n",
            "\n",
            "Epoch 2/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.9336950360839047 accuracy 0.5985074626865672\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.8495165082945753 accuracy 0.6970149253731344\n",
            "\n",
            "Epoch 3/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7789501129691281 accuracy 0.7820895522388059\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.7377567887306213 accuracy 0.8149253731343283\n",
            "\n",
            "Epoch 4/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6789636780966574 accuracy 0.8731343283582089\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6479358486275175 accuracy 0.9044776119402985\n",
            "\n",
            "Epoch 5/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6352002602904591 accuracy 0.917910447761194\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6275344998089235 accuracy 0.9238805970149254\n",
            "\n",
            "Epoch 6/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6243290260656557 accuracy 0.9283582089552239\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6244553007296662 accuracy 0.926865671641791\n",
            "\n",
            "Epoch 7/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6271523192747316 accuracy 0.9253731343283582\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6297116279602051 accuracy 0.9223880597014925\n",
            "\n",
            "Epoch 8/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6265800319500824 accuracy 0.9253731343283582\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6279946031855114 accuracy 0.9238805970149254\n",
            "\n",
            "Epoch 9/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.627056716982998 accuracy 0.9253731343283582\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6254006828834762 accuracy 0.926865671641791\n",
            "\n",
            "Epoch 10/10\n",
            "----------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6245529998594256 accuracy 0.9298507462686567\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss 0.6240434486474564 accuracy 0.9298507462686567\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "0aT_4aDi-R3o",
        "outputId": "7d7107a5-2843-4081-b9fd-6517b28c6fab"
      },
      "source": [
        "plt.plot(history['train_acc'], label='train accuracy')\n",
        "plt.plot(history['val_acc'], label='validation accuracy')\n",
        "\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1]);"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kkyZzH7-kgb",
        "outputId": "a44c0025-ae33-4a1f-ff2e-4b9f7567df74"
      },
      "source": [
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  test_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_test)\n",
        ")\n",
        "\n",
        "test_acc.item()"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5714285714285714"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gr9-8ubz-seU"
      },
      "source": [
        "review_text = \"I used to use Habitica, and I must say this is a great step up. I'd like to see more social features, such as sharing tasks - only oneperson has to perform said task for it to be checked off, but onlygiving that person the experience and gold. Otherwise, the price forsubscription is too steep, thus resulting in a sub-perfect score. Icould easily justify $0.99/month or eternal subscription for $15. Ifthat price could be met, as well as fine tuning, this would be easilyworth 5 stars.!!!\""
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kjspwagAoA_",
        "outputId": "50802219-6db2-463a-f05a-9675b16203e9"
      },
      "source": [
        "\n",
        "encoded_review = tokenizer.encode_plus(\n",
        "  review_text,\n",
        "  max_length=MAX_LEN,\n",
        "  add_special_tokens=True,\n",
        "  return_token_type_ids=False,\n",
        "  pad_to_max_length=True,\n",
        "  return_attention_mask=True,\n",
        "  return_tensors='pt',\n",
        ")"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2217: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wblm1Ub5ArAq",
        "outputId": "debe63f0-719e-4dfd-c17b-738af14c7c2e"
      },
      "source": [
        "input_ids = encoded_review['input_ids'].to(device)\n",
        "attention_mask = encoded_review['attention_mask'].to(device)\n",
        "\n",
        "output = model(input_ids, attention_mask)\n",
        "_, prediction = torch.max(output, dim=1)\n",
        "\n",
        "print(f'Review text: {review_text}')\n",
        "print(f'Sentiment  : {class_names[prediction]}')"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review text: I used to use Habitica, and I must say this is a great step up. I'd like to see more social features, such as sharing tasks - only oneperson has to perform said task for it to be checked off, but onlygiving that person the experience and gold. Otherwise, the price forsubscription is too steep, thus resulting in a sub-perfect score. Icould easily justify $0.99/month or eternal subscription for $15. Ifthat price could be met, as well as fine tuning, this would be easilyworth 5 stars.!!!\n",
            "Sentiment  : neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BonAf-zRB6wc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}